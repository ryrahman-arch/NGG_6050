{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8dC3uv+GYJLxJ0fohWG8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryrahman-arch/NGG_6050/blob/main/Rahman_Final_Presentation_Simulations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kAK7AdKGwxJ",
        "outputId": "49469c89-50f6-4310-8490-11f428452937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Group             Comparison  Pearson_Coefficient  Fisher_p_value\n",
            "0    WT   OSCAR_C1 vs Sall1_C2            -0.018173   1.381950e-293\n",
            "1    WT  OSCAR_C1 vs Anti_Iba1             0.012991   1.025169e-311\n",
            "2    KO   OSCAR_C1 vs Sall1_C2             0.031391    0.000000e+00\n",
            "3    KO  OSCAR_C1 vs Anti_Iba1             0.054181   5.196217e-312\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, fisher_exact\n",
        "\n",
        "# Parameters for the simulation\n",
        "num_samples = 50  # Number of samples per group\n",
        "prob_wt_higher = 0.9  # Probability that WT has higher colocalization than KO\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(40)\n",
        "\n",
        "# Mean fluorescence intensities for each stain\n",
        "mean_fluorescence = {\n",
        "    'OSCAR_C1': 100,\n",
        "    'Sall1_C2': 80,\n",
        "    'Anti_Iba1': 70\n",
        "}\n",
        "\n",
        "# Variance for simulated fluorescence intensity\n",
        "std_dev_fluorescence = 15\n",
        "\n",
        "# Generate data for WT and KO groups\n",
        "data = {'Group': [], 'Comparison': [], 'Pearson_Coefficient': [], 'Fisher_p_value': []}\n",
        "\n",
        "for group, adjustment in [('WT', prob_wt_higher), ('KO', 1 - prob_wt_higher)]:\n",
        "    for comparison in [('OSCAR_C1', 'Sall1_C2'), ('OSCAR_C1', 'Anti_Iba1')]:\n",
        "        stain1, stain2 = comparison\n",
        "\n",
        "        # Simulate pixel intensities for both stains\n",
        "        stain1_pixels = np.random.normal(mean_fluorescence[stain1] * adjustment, std_dev_fluorescence, 1000)\n",
        "        stain2_pixels = np.random.normal(mean_fluorescence[stain2] * adjustment, std_dev_fluorescence, 1000)\n",
        "\n",
        "        # Pearson's correlation coefficient\n",
        "        pearson_coeff, _ = pearsonr(stain1_pixels, stain2_pixels)\n",
        "\n",
        "        # Simulate binary colocalization data for Fisher's test\n",
        "        colocalized = np.random.choice([0, 1], size=1000, p=[1 - adjustment, adjustment])\n",
        "        non_colocalized = 1 - colocalized\n",
        "\n",
        "        # Create a contingency table for Fisher's exact test\n",
        "        fisher_table = np.array([[np.sum(colocalized), np.sum(non_colocalized)],\n",
        "                                 [np.sum(non_colocalized), np.sum(colocalized)]])\n",
        "        _, fisher_p_value = fisher_exact(fisher_table)\n",
        "\n",
        "        # Append results\n",
        "        data['Group'].append(group)\n",
        "        data['Comparison'].append(f\"{stain1} vs {stain2}\")\n",
        "        data['Pearson_Coefficient'].append(pearson_coeff)\n",
        "        data['Fisher_p_value'].append(fisher_p_value)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, fisher_exact\n",
        "\n",
        "# Parameters for the simulation\n",
        "num_samples = 5  # Number of samples per group\n",
        "high_correlation_wt = 0.9  # Target correlation for WT\n",
        "low_correlation_ko = 0.2  # Target correlation for KO\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Mean fluorescence intensities for each stain\n",
        "mean_fluorescence = {\n",
        "    'OSCAR_C1': 100,\n",
        "    'Sall1_C2': 80,\n",
        "    'Anti_Iba1': 70\n",
        "}\n",
        "\n",
        "# Variance for simulated fluorescence intensity\n",
        "std_dev_fluorescence = 15\n",
        "\n",
        "# Generate data for WT and KO groups\n",
        "data = {'Group': [], 'Sample': [], 'Comparison': [], 'Pearson_Coefficient': [], 'Fisher_p_value': []}\n",
        "\n",
        "for group, correlation in [('WT', high_correlation_wt), ('KO', low_correlation_ko)]:\n",
        "    for comparison in [('OSCAR_C1', 'Sall1_C2'), ('OSCAR_C1', 'Anti_Iba1')]:\n",
        "        stain1, stain2 = comparison\n",
        "\n",
        "        for sample_idx in range(1, num_samples + 1):\n",
        "            # Simulate pixel intensities for both stains\n",
        "            stain1_pixels = np.random.normal(mean_fluorescence[stain1], std_dev_fluorescence, 1000)\n",
        "\n",
        "            # Introduce correlation for the second stain\n",
        "            noise = np.random.normal(0, std_dev_fluorescence * (1 - correlation), 1000)\n",
        "            stain2_pixels = stain1_pixels * correlation + noise\n",
        "\n",
        "            # Pearson's correlation coefficient\n",
        "            pearson_coeff, _ = pearsonr(stain1_pixels, stain2_pixels)\n",
        "\n",
        "            # Simulate binary colocalization data for Fisher's test\n",
        "            colocalized = np.random.choice([0, 1], size=1000, p=[1 - correlation, correlation])\n",
        "            non_colocalized = 1 - colocalized\n",
        "\n",
        "            # Create a contingency table for Fisher's exact test\n",
        "            fisher_table = np.array([[np.sum(colocalized), np.sum(non_colocalized)],\n",
        "                                     [np.sum(non_colocalized), np.sum(colocalized)]])\n",
        "            _, fisher_p_value = fisher_exact(fisher_table)\n",
        "\n",
        "            # Append results\n",
        "            data['Group'].append(group)\n",
        "            data['Sample'].append(sample_idx)\n",
        "            data['Comparison'].append(f\"{stain1} vs {stain2}\")\n",
        "            data['Pearson_Coefficient'].append(pearson_coeff)\n",
        "            data['Fisher_p_value'].append(fisher_p_value)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBF_tEv6I08_",
        "outputId": "5af4b6d2-425d-4881-eef4-39387a0dfc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Group  Sample             Comparison  Pearson_Coefficient  Fisher_p_value\n",
            "0     WT       1   OSCAR_C1 vs Sall1_C2             0.993608   1.534984e-302\n",
            "1     WT       2   OSCAR_C1 vs Sall1_C2             0.994456   2.338824e-304\n",
            "2     WT       3   OSCAR_C1 vs Sall1_C2             0.993447    0.000000e+00\n",
            "3     WT       4   OSCAR_C1 vs Sall1_C2             0.993831   2.487617e-317\n",
            "4     WT       5   OSCAR_C1 vs Sall1_C2             0.994140    0.000000e+00\n",
            "5     WT       1  OSCAR_C1 vs Anti_Iba1             0.993843    0.000000e+00\n",
            "6     WT       2  OSCAR_C1 vs Anti_Iba1             0.993903    0.000000e+00\n",
            "7     WT       3  OSCAR_C1 vs Anti_Iba1             0.994154   2.487617e-317\n",
            "8     WT       4  OSCAR_C1 vs Anti_Iba1             0.995046    0.000000e+00\n",
            "9     WT       5  OSCAR_C1 vs Anti_Iba1             0.994139    0.000000e+00\n",
            "10    KO       1   OSCAR_C1 vs Sall1_C2             0.220841   1.750782e-165\n",
            "11    KO       2   OSCAR_C1 vs Sall1_C2             0.191301   4.036041e-163\n",
            "12    KO       3   OSCAR_C1 vs Sall1_C2             0.262868   7.262872e-179\n",
            "13    KO       4   OSCAR_C1 vs Sall1_C2             0.209140   7.648324e-212\n",
            "14    KO       5   OSCAR_C1 vs Sall1_C2             0.231971   1.287770e-191\n",
            "15    KO       1  OSCAR_C1 vs Anti_Iba1             0.286402   4.036041e-163\n",
            "16    KO       2  OSCAR_C1 vs Anti_Iba1             0.198357   6.743394e-184\n",
            "17    KO       3  OSCAR_C1 vs Anti_Iba1             0.284033   6.743394e-184\n",
            "18    KO       4  OSCAR_C1 vs Anti_Iba1             0.249884   1.518214e-199\n",
            "19    KO       5  OSCAR_C1 vs Anti_Iba1             0.275108   1.061523e-172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, fisher_exact\n",
        "\n",
        "# Parameters for the simulation\n",
        "num_samples = 5  # Number of samples per group\n",
        "high_correlation_wt = 0.7  # Target correlation for WT (reduced for more noise)\n",
        "low_correlation_ko = 0.2  # Target correlation for KO\n",
        "high_colocalization_prob_wt = 0.9  # Probability of colocalized pixels in WT\n",
        "low_colocalization_prob_ko = 0.1  # Probability of colocalized pixels in KO\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Mean fluorescence intensities for each stain\n",
        "mean_fluorescence = {\n",
        "    'OSCAR_C1': 100,\n",
        "    'Sall1_C2': 80,\n",
        "    'Anti_Iba1': 70\n",
        "}\n",
        "\n",
        "# Higher variance for noisier fluorescence intensity\n",
        "std_dev_fluorescence = 25\n",
        "\n",
        "# Generate data for WT and KO groups\n",
        "data = {'Group': [], 'Sample': [], 'Comparison': [], 'Pearson_Coefficient': [], 'Fisher_p_value': []}\n",
        "\n",
        "for group, (correlation, colocalization_prob) in [('WT', (high_correlation_wt, high_colocalization_prob_wt)),\n",
        "                                                  ('KO', (low_correlation_ko, low_colocalization_prob_ko))]:\n",
        "    for comparison in [('OSCAR_C1', 'Sall1_C2'), ('OSCAR_C1', 'Anti_Iba1')]:\n",
        "        stain1, stain2 = comparison\n",
        "\n",
        "        for sample_idx in range(1, num_samples + 1):\n",
        "            # Simulate pixel intensities for both stains\n",
        "            stain1_pixels = np.random.normal(mean_fluorescence[stain1], std_dev_fluorescence, 1000)\n",
        "\n",
        "            # Introduce noisier correlation for the second stain\n",
        "            noise = np.random.normal(0, std_dev_fluorescence * (1 - correlation), 1000)\n",
        "            stain2_pixels = stain1_pixels * correlation + noise\n",
        "\n",
        "            # Pearson's correlation coefficient\n",
        "            pearson_coeff, _ = pearsonr(stain1_pixels, stain2_pixels)\n",
        "\n",
        "            # Simulate noisier binary colocalization data for Fisher's test\n",
        "            colocalized = np.random.choice([0, 1], size=5, p=[1 - colocalization_prob, colocalization_prob])\n",
        "            non_colocalized = 1 - colocalized\n",
        "\n",
        "            # Create a contingency table for Fisher's exact test\n",
        "            fisher_table = np.array([[np.sum(colocalized), np.sum(non_colocalized)],\n",
        "                                     [np.sum(non_colocalized), np.sum(colocalized)]])\n",
        "            _, fisher_p_value = fisher_exact(fisher_table)\n",
        "\n",
        "            # Append results\n",
        "            data['Group'].append(group)\n",
        "            data['Sample'].append(sample_idx)\n",
        "            data['Comparison'].append(f\"{stain1} vs {stain2}\")\n",
        "            data['Pearson_Coefficient'].append(pearson_coeff)\n",
        "            data['Fisher_p_value'].append(fisher_p_value)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ThCZotDNvPF",
        "outputId": "e8b99bc3-8f69-4936-b1be-4a7dfa9e9c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Group  Sample             Comparison  Pearson_Coefficient  Fisher_p_value\n",
            "0     WT       1   OSCAR_C1 vs Sall1_C2             0.913953        0.206349\n",
            "1     WT       2   OSCAR_C1 vs Sall1_C2             0.917793        0.206349\n",
            "2     WT       3   OSCAR_C1 vs Sall1_C2             0.914886        0.007937\n",
            "3     WT       4   OSCAR_C1 vs Sall1_C2             0.916603        0.206349\n",
            "4     WT       5   OSCAR_C1 vs Sall1_C2             0.924673        0.007937\n",
            "5     WT       1  OSCAR_C1 vs Anti_Iba1             0.907917        0.007937\n",
            "6     WT       2  OSCAR_C1 vs Anti_Iba1             0.913013        0.206349\n",
            "7     WT       3  OSCAR_C1 vs Anti_Iba1             0.913220        0.007937\n",
            "8     WT       4  OSCAR_C1 vs Anti_Iba1             0.912917        0.206349\n",
            "9     WT       5  OSCAR_C1 vs Anti_Iba1             0.914778        0.206349\n",
            "10    KO       1   OSCAR_C1 vs Sall1_C2             0.260518        0.007937\n",
            "11    KO       2   OSCAR_C1 vs Sall1_C2             0.244901        0.007937\n",
            "12    KO       3   OSCAR_C1 vs Sall1_C2             0.287152        0.007937\n",
            "13    KO       4   OSCAR_C1 vs Sall1_C2             0.209410        0.206349\n",
            "14    KO       5   OSCAR_C1 vs Sall1_C2             0.212279        0.206349\n",
            "15    KO       1  OSCAR_C1 vs Anti_Iba1             0.291307        0.007937\n",
            "16    KO       2  OSCAR_C1 vs Anti_Iba1             0.235614        0.007937\n",
            "17    KO       3  OSCAR_C1 vs Anti_Iba1             0.242293        0.007937\n",
            "18    KO       4  OSCAR_C1 vs Anti_Iba1             0.212003        0.206349\n",
            "19    KO       5  OSCAR_C1 vs Anti_Iba1             0.254172        0.206349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, fisher_exact\n",
        "\n",
        "# Parameters for the simulation\n",
        "num_samples = 5  # Number of samples per group\n",
        "high_correlation_wt = 0.7  # Target correlation for WT\n",
        "low_correlation_ko = 0.2  # Target correlation for KO\n",
        "high_colocalization_prob_wt = 0.9  # High probability of colocalized cells in WT\n",
        "low_colocalization_prob_ko = 0.2  # Low probability of colocalized cells in KO\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Mean fluorescence intensities for each stain\n",
        "mean_fluorescence = {\n",
        "    'OSCAR_C1': 100,\n",
        "    'Sall1_C2': 80,\n",
        "    'Anti_Iba1': 70\n",
        "}\n",
        "\n",
        "# Variance for simulated fluorescence intensity\n",
        "std_dev_fluorescence = 25\n",
        "\n",
        "# Generate data for WT and KO groups\n",
        "data = {'Group': [], 'Sample': [], 'Comparison': [], 'Pearson_Coefficient': [], 'Fisher_p_value': []}\n",
        "\n",
        "for group, (correlation, colocalization_prob) in [('WT', (high_correlation_wt, high_colocalization_prob_wt)),\n",
        "                                                  ('KO', (low_correlation_ko, low_colocalization_prob_ko))]:\n",
        "    for comparison in [('OSCAR_C1', 'Sall1_C2'), ('OSCAR_C1', 'Anti_Iba1')]:\n",
        "        stain1, stain2 = comparison\n",
        "\n",
        "        for sample_idx in range(1, num_samples + 1):\n",
        "            # Simulate pixel intensities for both stains\n",
        "            stain1_pixels = np.random.normal(mean_fluorescence[stain1], std_dev_fluorescence, 1000)\n",
        "\n",
        "            # Introduce noisier correlation for the second stain\n",
        "            noise = np.random.normal(0, std_dev_fluorescence * (1 - correlation), 1000)\n",
        "            stain2_pixels = stain1_pixels * correlation + noise\n",
        "\n",
        "            # Pearson's correlation coefficient\n",
        "            pearson_coeff, _ = pearsonr(stain1_pixels, stain2_pixels)\n",
        "\n",
        "            # Simulate binary colocalization data for Fisher's test\n",
        "            colocalized = np.random.choice([1, 0], size=7, p=[colocalization_prob, 1 - colocalization_prob])\n",
        "            non_colocalized = 1 - colocalized\n",
        "\n",
        "            # Create a separate contingency table for WT and KO\n",
        "            colocalized_count = np.sum(colocalized)\n",
        "            non_colocalized_count = np.sum(non_colocalized)\n",
        "            fisher_table = np.array([[colocalized_count, non_colocalized_count],\n",
        "                                     [non_colocalized_count, colocalized_count]])\n",
        "            _, fisher_p_value = fisher_exact(fisher_table)\n",
        "\n",
        "            # Append results\n",
        "            data['Group'].append(group)\n",
        "            data['Sample'].append(sample_idx)\n",
        "            data['Comparison'].append(f\"{stain1} vs {stain2}\")\n",
        "            data['Pearson_Coefficient'].append(pearson_coeff)\n",
        "            data['Fisher_p_value'].append(fisher_p_value)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFqphTAqSheu",
        "outputId": "509ea9d9-2be6-47cd-b3ff-d23dd6e67007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Group  Sample             Comparison  Pearson_Coefficient  Fisher_p_value\n",
            "0     WT       1   OSCAR_C1 vs Sall1_C2             0.913953        0.029138\n",
            "1     WT       2   OSCAR_C1 vs Sall1_C2             0.917793        0.029138\n",
            "2     WT       3   OSCAR_C1 vs Sall1_C2             0.914479        0.029138\n",
            "3     WT       4   OSCAR_C1 vs Sall1_C2             0.916804        0.029138\n",
            "4     WT       5   OSCAR_C1 vs Sall1_C2             0.924341        0.029138\n",
            "5     WT       1  OSCAR_C1 vs Anti_Iba1             0.907598        0.029138\n",
            "6     WT       2  OSCAR_C1 vs Anti_Iba1             0.913528        0.000583\n",
            "7     WT       3  OSCAR_C1 vs Anti_Iba1             0.913012        0.000583\n",
            "8     WT       4  OSCAR_C1 vs Anti_Iba1             0.913061        0.029138\n",
            "9     WT       5  OSCAR_C1 vs Anti_Iba1             0.914977        0.000583\n",
            "10    KO       1   OSCAR_C1 vs Sall1_C2             0.263390        0.000583\n",
            "11    KO       2   OSCAR_C1 vs Sall1_C2             0.243431        1.000000\n",
            "12    KO       3   OSCAR_C1 vs Sall1_C2             0.292759        0.029138\n",
            "13    KO       4   OSCAR_C1 vs Sall1_C2             0.202207        0.000583\n",
            "14    KO       5   OSCAR_C1 vs Sall1_C2             0.212769        0.000583\n",
            "15    KO       1  OSCAR_C1 vs Anti_Iba1             0.295423        0.286131\n",
            "16    KO       2  OSCAR_C1 vs Anti_Iba1             0.232500        0.000583\n",
            "17    KO       3  OSCAR_C1 vs Anti_Iba1             0.240680        0.029138\n",
            "18    KO       4  OSCAR_C1 vs Anti_Iba1             0.212679        0.000583\n",
            "19    KO       5  OSCAR_C1 vs Anti_Iba1             0.250420        0.286131\n"
          ]
        }
      ]
    }
  ]
}